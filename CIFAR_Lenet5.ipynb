{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemaedahrav/CNN_Accelerators/blob/main/CIFAR_Lenet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jcLmru1wjKSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3c8c28-115a-4100-d5f1-c53313542dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.6.5)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import sys\n",
        "\n",
        "import PIL\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from statistics import mean\n",
        "from collections  import OrderedDict\n",
        "import numpy as np\n",
        "from skimage import io, transform\n",
        "import random\n",
        "import scipy\n",
        "import cv2\n",
        "from math import floor, ceil\n",
        "from datetime import datetime\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "%matplotlib inline\n",
        "DEVICE = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HQyRt_xdjKSs"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.Resize((32, 32)),\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                                transforms.Grayscale(num_output_channels=1), \n",
        "                               ])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeqH5b2kn0GU",
        "outputId": "4a33c771-b013-474e-c52c-a6dfad01daea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 100\n",
        "N_EPOCHS = 15\n",
        "IMG_SIZE = 32\n",
        "N_CLASSES = 10"
      ],
      "metadata": {
        "id": "iYv3NNcY2_q6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mDGH0MkbjKSs"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, data_loader, device):\n",
        "\n",
        "    correct_pred = 0 \n",
        "    n = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y_true in data_loader:\n",
        "\n",
        "            X = X.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "\n",
        "            _, y_prob = model(X)\n",
        "            _, predicted_labels = torch.max(y_prob, 1)\n",
        "\n",
        "            n += y_true.size(0)\n",
        "            correct_pred += (predicted_labels == y_true).sum()\n",
        "\n",
        "    return correct_pred.float() / n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, device):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    \n",
        "    for X, y_true in train_loader:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        X = X.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "    \n",
        "        # Forward pass\n",
        "        y_hat, _ = model(X) \n",
        "        loss = criterion(y_hat, y_true) \n",
        "        running_loss += loss.item() * X.size(0)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return model, optimizer, epoch_loss"
      ],
      "metadata": {
        "id": "eMJKAH-R4tKq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, criterion, optimizer, train_loader, epochs, device, print_every=1):\n",
        "\n",
        "    best_loss = 1e10\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        if epoch % print_every == (print_every - 1):\n",
        "            \n",
        "            train_acc = get_accuracy(model, train_loader, device=device)\n",
        "                \n",
        "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
        "                  f'Epoch: {epoch}\\t'\n",
        "                  f'Train loss: {train_loss:.4f}\\t'\n",
        "                  f'Train accuracy: {100 * train_acc:.2f}')\n",
        "    \n",
        "    return model, optimizer, train_losses"
      ],
      "metadata": {
        "id": "I14VaIDl3GSi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WqqEUIr0jKSx"
      },
      "outputs": [],
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=84, kernel_size=5, stride=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=84, out_features=64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=64, out_features=n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.classifier(x)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return logits, probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2eeQ03hfjKSx"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = LeNet5(N_CLASSES)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x47gqYiqjKSx"
      },
      "outputs": [],
      "source": [
        "#model, optimizer, _ = training_loop(model, criterion, optimizer, trainloader, N_EPOCHS, DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(15):\n",
        "    running_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "        optimizer.zero_grad()\n",
        "        logits, output = model(inputs)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        end_time = time.time()\n",
        "        time_taken = end_time - start_time\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    \n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            print('Time:',time_taken)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training of LeNet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrpkJUB--VbE",
        "outputId": "339dea91-5d27-4a6c-cac6-1af951f96268"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.224\n",
            "Time: 18.368669509887695\n",
            "[1,  4000] loss: 2.156\n",
            "Time: 32.56694984436035\n",
            "[1,  6000] loss: 2.117\n",
            "Time: 46.82336616516113\n",
            "[1,  8000] loss: 2.084\n",
            "Time: 61.35168170928955\n",
            "[1, 10000] loss: 2.077\n",
            "Time: 76.23940467834473\n",
            "[1, 12000] loss: 2.067\n",
            "Time: 90.36059737205505\n",
            "[2,  2000] loss: 2.047\n",
            "Time: 14.348697662353516\n",
            "[2,  4000] loss: 2.041\n",
            "Time: 28.631542205810547\n",
            "[2,  6000] loss: 2.038\n",
            "Time: 42.99597215652466\n",
            "[2,  8000] loss: 2.019\n",
            "Time: 57.37296104431152\n",
            "[2, 10000] loss: 2.008\n",
            "Time: 71.67338442802429\n",
            "[2, 12000] loss: 2.016\n",
            "Time: 85.99613833427429\n",
            "[3,  2000] loss: 1.994\n",
            "Time: 14.197701215744019\n",
            "[3,  4000] loss: 1.998\n",
            "Time: 28.392746925354004\n",
            "[3,  6000] loss: 1.991\n",
            "Time: 42.632025718688965\n",
            "[3,  8000] loss: 1.991\n",
            "Time: 56.84504199028015\n",
            "[3, 10000] loss: 1.990\n",
            "Time: 71.0653395652771\n",
            "[3, 12000] loss: 2.002\n",
            "Time: 85.32175707817078\n",
            "[4,  2000] loss: 1.964\n",
            "Time: 14.33860182762146\n",
            "[4,  4000] loss: 1.974\n",
            "Time: 30.301779985427856\n",
            "[4,  6000] loss: 1.963\n",
            "Time: 44.64423727989197\n",
            "[4,  8000] loss: 1.976\n",
            "Time: 58.98563241958618\n",
            "[4, 10000] loss: 1.989\n",
            "Time: 73.97019672393799\n",
            "[4, 12000] loss: 1.987\n",
            "Time: 88.84232187271118\n",
            "[5,  2000] loss: 1.966\n",
            "Time: 14.834473133087158\n",
            "[5,  4000] loss: 1.951\n",
            "Time: 29.399471759796143\n",
            "[5,  6000] loss: 1.964\n",
            "Time: 44.50980353355408\n",
            "[5,  8000] loss: 1.972\n",
            "Time: 59.28736877441406\n",
            "[5, 10000] loss: 1.949\n",
            "Time: 74.17677736282349\n",
            "[5, 12000] loss: 1.945\n",
            "Time: 89.23900580406189\n",
            "[6,  2000] loss: 1.948\n",
            "Time: 15.16282343864441\n",
            "[6,  4000] loss: 1.932\n",
            "Time: 30.65011692047119\n",
            "[6,  6000] loss: 1.948\n",
            "Time: 46.283377170562744\n",
            "[6,  8000] loss: 1.947\n",
            "Time: 62.32039785385132\n",
            "[6, 10000] loss: 1.942\n",
            "Time: 78.41540813446045\n",
            "[6, 12000] loss: 1.966\n",
            "Time: 94.74451494216919\n",
            "[7,  2000] loss: 1.940\n",
            "Time: 16.340277433395386\n",
            "[7,  4000] loss: 1.947\n",
            "Time: 32.575456857681274\n",
            "[7,  6000] loss: 1.933\n",
            "Time: 49.21812725067139\n",
            "[7,  8000] loss: 1.950\n",
            "Time: 65.67373442649841\n",
            "[7, 10000] loss: 1.946\n",
            "Time: 82.13891649246216\n",
            "[7, 12000] loss: 1.939\n",
            "Time: 98.69566559791565\n",
            "[8,  2000] loss: 1.928\n",
            "Time: 16.773873567581177\n",
            "[8,  4000] loss: 1.934\n",
            "Time: 33.20055890083313\n",
            "[8,  6000] loss: 1.935\n",
            "Time: 49.780049324035645\n",
            "[8,  8000] loss: 1.924\n",
            "Time: 66.32691526412964\n",
            "[8, 10000] loss: 1.934\n",
            "Time: 82.89611792564392\n",
            "[8, 12000] loss: 1.941\n",
            "Time: 99.37099862098694\n",
            "[9,  2000] loss: 1.929\n",
            "Time: 16.484657526016235\n",
            "[9,  4000] loss: 1.936\n",
            "Time: 32.946073055267334\n",
            "[9,  6000] loss: 1.924\n",
            "Time: 49.516292095184326\n",
            "[9,  8000] loss: 1.928\n",
            "Time: 66.18000602722168\n",
            "[9, 10000] loss: 1.926\n",
            "Time: 82.7314522266388\n",
            "[9, 12000] loss: 1.926\n",
            "Time: 99.3138906955719\n",
            "[10,  2000] loss: 1.916\n",
            "Time: 16.54493021965027\n",
            "[10,  4000] loss: 1.929\n",
            "Time: 33.08261322975159\n",
            "[10,  6000] loss: 1.911\n",
            "Time: 49.67867159843445\n",
            "[10,  8000] loss: 1.916\n",
            "Time: 66.01986861228943\n",
            "[10, 10000] loss: 1.927\n",
            "Time: 82.35086512565613\n",
            "[10, 12000] loss: 1.920\n",
            "Time: 99.03423738479614\n",
            "[11,  2000] loss: 1.917\n",
            "Time: 16.734832048416138\n",
            "[11,  4000] loss: 1.914\n",
            "Time: 33.34586215019226\n",
            "[11,  6000] loss: 1.921\n",
            "Time: 49.7171573638916\n",
            "[11,  8000] loss: 1.916\n",
            "Time: 66.07743263244629\n",
            "[11, 10000] loss: 1.929\n",
            "Time: 82.48923397064209\n",
            "[11, 12000] loss: 1.918\n",
            "Time: 98.94907355308533\n",
            "[12,  2000] loss: 1.911\n",
            "Time: 16.327352285385132\n",
            "[12,  4000] loss: 1.915\n",
            "Time: 32.88806509971619\n",
            "[12,  6000] loss: 1.912\n",
            "Time: 49.40435171127319\n",
            "[12,  8000] loss: 1.915\n",
            "Time: 65.92566108703613\n",
            "[12, 10000] loss: 1.916\n",
            "Time: 82.42294311523438\n",
            "[12, 12000] loss: 1.913\n",
            "Time: 98.97685885429382\n",
            "[13,  2000] loss: 1.907\n",
            "Time: 16.582529067993164\n",
            "[13,  4000] loss: 1.916\n",
            "Time: 33.175485134124756\n",
            "[13,  6000] loss: 1.901\n",
            "Time: 49.85551929473877\n",
            "[13,  8000] loss: 1.913\n",
            "Time: 66.55731701850891\n",
            "[13, 10000] loss: 1.919\n",
            "Time: 83.18251395225525\n",
            "[13, 12000] loss: 1.915\n",
            "Time: 100.02036571502686\n",
            "[14,  2000] loss: 1.906\n",
            "Time: 16.82341957092285\n",
            "[14,  4000] loss: 1.911\n",
            "Time: 33.329105377197266\n",
            "[14,  6000] loss: 1.921\n",
            "Time: 49.71125507354736\n",
            "[14,  8000] loss: 1.906\n",
            "Time: 66.0638062953949\n",
            "[14, 10000] loss: 1.912\n",
            "Time: 82.42254161834717\n",
            "[14, 12000] loss: 1.920\n",
            "Time: 98.78602623939514\n",
            "[15,  2000] loss: 1.908\n",
            "Time: 16.603200912475586\n",
            "[15,  4000] loss: 1.902\n",
            "Time: 32.912580728530884\n",
            "[15,  6000] loss: 1.917\n",
            "Time: 49.17236590385437\n",
            "[15,  8000] loss: 1.921\n",
            "Time: 65.49913620948792\n",
            "[15, 10000] loss: 1.920\n",
            "Time: 82.02859783172607\n",
            "[15, 12000] loss: 1.915\n",
            "Time: 98.32768034934998\n",
            "Finished Training of LeNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = get_accuracy(model, testloader, DEVICE)\n",
        "print('Accuracy of the network on the 10000 test images:', test_accuracy)"
      ],
      "metadata": {
        "id": "hIdQnyD93GXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330a385d-e39f-4d88-f207-f990fb2978c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: tensor(0.5212)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "torch.save(model.state_dict(), 'LeNet_CIFAR.pth')\n",
        "files.download('LeNet_CIFAR.pth')"
      ],
      "metadata": {
        "id": "r-N1xQ2Qzx7S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4a3bd30a-f332-41d8-d228-07ad6b1db82e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f77fece-29eb-489b-85c6-6d9d724feb3c\", \"LeNet_CIFAR.pth\", 172615)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "CIFAR_Lenet5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}